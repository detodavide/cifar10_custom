2023-08-12 17:36:01,776 - worker_process - INFO - Worker_process started.
2023-08-12 17:36:01,804 - HEModelEncryptor - INFO - Using HE model encryptor.
2023-08-12 17:36:01,805 - HEModelEncryptor - INFO - client weights control: {}
2023-08-12 17:36:01,805 - HEModelEncryptor - INFO - Encrypting all layers
2023-08-12 17:36:01,805 - HEModelEncryptor - INFO - Using HE model encryptor.
2023-08-12 17:36:01,805 - HEModelEncryptor - INFO - client weights control: {}
2023-08-12 17:36:01,805 - HEModelEncryptor - INFO - Encrypting all layers
2023-08-12 17:36:01,806 - HEModelDecryptor - INFO - Using HE model decryptor.
2023-08-12 17:36:01,888 - Cell - INFO - site-3.f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224: created backbone internal connector to tcp://localhost:40655 on parent
2023-08-12 17:36:01,891 - Cell - INFO - site-3.f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224: created backbone external connector to grpc://localhost:8102
2023-08-12 17:36:01,891 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00001 ACTIVE tcp://localhost:40655] is starting
2023-08-12 17:36:01,891 - nvflare.fuel.f3.sfm.conn_manager - INFO - Connector [CH00002 ACTIVE grpc://localhost:8102] is starting
2023-08-12 17:36:01,891 - FederatedClient - INFO - Wait for client_runner to be created.
2023-08-12 17:36:01,892 - FederatedClient - INFO - Got client_runner after 0.0005850791931152344 seconds
2023-08-12 17:36:01,892 - FederatedClient - INFO - Got the new primary SP: grpc://localhost:8102
2023-08-12 17:36:01,945 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: client runner started
2023-08-12 17:36:04,097 - Communicator - INFO - Received from secure_project server  (13970221 Bytes). getTask: train time: 0.1319875717163086 seconds
2023-08-12 17:36:04,097 - FederatedClient - INFO - pull_task completed. Task name:train Status:True 
2023-08-12 17:36:04,098 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: got task assignment: name=train, id=a4870ee9-cfb2-401e-8e45-bf63064f5444
2023-08-12 17:36:04,098 - HEModelDecryptor - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Running decryption...
2023-08-12 17:36:04,098 - HEModelDecryptor - WARNING - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: DXO does not contain PROCESSED_KEYS (do nothing). Note, this is normal in the first round of training, as the initial global model is not encrypted.
2023-08-12 17:36:04,098 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: invoking task executor LearnerExecutor
2023-08-12 17:36:04,098 - LearnerExecutor - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Client trainer got task: train
2023-08-12 17:36:04,098 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Client site-3 initialized at 
 /home/deto/Desktop/Projects/cifar10_v1/cifar10-real-world/workspaces/secure_workspace/site-3/startup/../f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224/app_site-3 
 with args: Namespace(workspace='/home/deto/Desktop/Projects/cifar10_v1/cifar10-real-world/workspaces/secure_workspace/site-3/startup/..', startup='/home/deto/Desktop/Projects/cifar10_v1/cifar10-real-world/workspaces/secure_workspace/site-3/startup/../startup', token='cea77170-9711-427a-8ea3-fd9e04232fd7', ssid='ebc6125d-0a56-4688-9b08-355fe9e4d61a', job_id='f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224', client_name='site-3', sp_target='localhost:8102', parent_url='tcp://localhost:40655', fed_client='fed_client.json', set=['secure_train=true', 'uid=site-3', 'org=nvidia', 'config_folder=config', 'print_conf=True'], local_rank=0, train_config='config/config_train.json', client_config='config/config_fed_client.json', config_folder='config', env='config/environment.json')
2023-08-12 17:36:05,669 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: IndexList Path: /tmp/cifar10_splits/cifar10_fedavg_he_alpha1.0_8d7cbf33-e4a5-4ae9-9235-cdaace4f85bc/site-3.npy
2023-08-12 17:36:05,670 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Loading subset index
2023-08-12 17:36:05,670 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Client subset size: 6653
2023-08-12 17:36:06,336 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Client identity: site-3
2023-08-12 17:36:09,637 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: val_acc_global_model (global_model): 0.1
2023-08-12 17:36:09,637 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Current/Total Round: 1/10
2023-08-12 17:36:09,637 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Client identity: site-3
2023-08-12 17:36:09,640 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Local steps per epoch: 104
2023-08-12 17:36:09,642 - CIFAR10Learner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: Local epoch site-3: 1/4 (lr=0.01)
2023-08-12 17:36:09,776 - ClientRunner - ERROR - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: RuntimeError from executor LearnerExecutor: OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.78 GiB total capacity; 107.05 MiB already allocated; 25.88 MiB free; 116.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF: Aborting the job!
2023-08-12 17:36:09,778 - ClientRunner - ERROR - Traceback (most recent call last):
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/nvflare/private/fed/client/client_runner.py", line 254, in _process_task
    reply = executor.execute(task.name, task.data, fl_ctx, self.task_abort_signal)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/nvflare/app_common/executors/learner_executor.py", line 85, in execute
    return self.train(shareable, fl_ctx, abort_signal)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/nvflare/app_common/executors/learner_executor.py", line 100, in train
    train_result = self.learner.train(shareable, fl_ctx, abort_signal)
  File "/home/deto/Desktop/Projects/cifar10_v1/cifar10-real-world/workspaces/secure_workspace/site-3/local/custom/pt/learners/cifar10_learner.py", line 293, in train
    self.local_train(
  File "/home/deto/Desktop/Projects/cifar10_v1/cifar10-real-world/workspaces/secure_workspace/site-3/local/custom/pt/learners/cifar10_learner.py", line 222, in local_train
    outputs = self.model(inputs)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/deto/Desktop/Projects/cifar10_v1/cifar10-real-world/workspaces/secure_workspace/site-3/local/custom/pt/networks/cifar10_nets.py", line 105, in forward
    x = self.fc_layer(x)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/deto/Desktop/Projects/environments/nvflare-venv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.78 GiB total capacity; 107.05 MiB already allocated; 25.88 MiB free; 116.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2023-08-12 17:36:09,779 - FederatedClient - INFO - Starting to push execute result.
2023-08-12 17:36:09,784 - Communicator - INFO -  SubmitUpdate size: 648 Bytes. time: 0.004388332366943359 seconds
2023-08-12 17:36:09,784 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, task_name=train, task_id=a4870ee9-cfb2-401e-8e45-bf63064f5444]: result sent to server for task: name=train, id=a4870ee9-cfb2-401e-8e45-bf63064f5444
2023-08-12 17:36:10,016 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224, peer=secure_project, peer_run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: received aux request from Server to end current RUN
2023-08-12 17:36:10,016 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: ABORT (RUN) command received
2023-08-12 17:36:10,016 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: ABORT (RUN) requests end run events sequence
2023-08-12 17:36:10,016 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: ABOUT_TO_END_RUN fired
2023-08-12 17:36:10,018 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: END_RUN fired
2023-08-12 17:36:11,787 - ClientRunner - INFO - [identity=site-3, run=f5eba1bb-382e-4ce8-bf5f-9ec0b8a62224]: run method requests end run events sequence
2023-08-12 17:36:11,802 - FederatedClient - INFO - Shutting down client run: site-3
2023-08-12 17:36:14,392 - MPM - INFO - MPM: Good Bye!
